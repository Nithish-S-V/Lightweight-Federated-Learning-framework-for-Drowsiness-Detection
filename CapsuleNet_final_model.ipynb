{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "e30e2e10-a909-485d-be9d-dc6f592911a7",
    "_uuid": "c7e569699c6d067cd9fdf9c77299775e399b2ef3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qWnuqFe2o8x2",
    "outputId": "5da50037-4aa3-47db-83e1-42db3eae5305"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras import callbacks\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import callbacks\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "167d39ca-ee32-4eec-a83b-86194252b14f",
    "_uuid": "90c180a9a8c20e3fb8a93c3eb42588927cfcd6b6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "dQti96GTo8x5",
    "outputId": "73dd133a-5bc2-47f2-ea08-c4de4c135fdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# The following is another way to implement primary capsule layer. This is much slower.\\n# Apply Conv2D `n_channels` times and concatenate all capsules\\ndef PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\\n    outputs = []\\n    for _ in range(n_channels):\\n        output = layers.Conv2D(filters=dim_capsule, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\\n        outputs.append(layers.Reshape([output.get_shape().as_list()[1] ** 2, dim_capsule])(output))\\n    outputs = layers.Concatenate(axis=1)(outputs)\\n    return layers.Lambda(squash)(outputs)\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import initializers, layers\n",
    "\n",
    "\n",
    "class Length(layers.Layer):\n",
    "    \"\"\"\n",
    "    Compute the length of vectors. This is used to compute a Tensor that has the same shape with y_true in margin_loss.\n",
    "    Using this layer as model's output can directly predict labels by using `y_pred = np.argmax(model.predict(x), 1)`\n",
    "    inputs: shape=[None, num_vectors, dim_vector]\n",
    "    output: shape=[None, num_vectors]\n",
    "    \"\"\"\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return tf.sqrt(tf.reduce_sum(tf.square(inputs), -1) + K.epsilon())\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Length, self).get_config()\n",
    "        return config\n",
    "\n",
    "\n",
    "class Mask(layers.Layer):\n",
    "    \"\"\"\n",
    "    Mask a Tensor with shape=[None, num_capsule, dim_vector] either by the capsule with max length or by an additional \n",
    "    input mask. Except the max-length capsule (or specified capsule), all vectors are masked to zeros. Then flatten the\n",
    "    masked Tensor.\n",
    "    For example:\n",
    "        ```\n",
    "        x = keras.layers.Input(shape=[8, 3, 2])  # batch_size=8, each sample contains 3 capsules with dim_vector=2\n",
    "        y = keras.layers.Input(shape=[8, 3])  # True labels. 8 samples, 3 classes, one-hot coding.\n",
    "        out = Mask()(x)  # out.shape=[8, 6]\n",
    "        # or\n",
    "        out2 = Mask()([x, y])  # out2.shape=[8,6]. Masked with true labels y. Of course y can also be manipulated.\n",
    "        ```\n",
    "    \"\"\"\n",
    "    def call(self, inputs, **kwargs):\n",
    "        if type(inputs) is list:  # true label is provided with shape = [None, n_classes], i.e. one-hot code.\n",
    "            assert len(inputs) == 2\n",
    "            inputs, mask = inputs\n",
    "        else:  # if no true label, mask by the max length of capsules. Mainly used for prediction\n",
    "            # compute lengths of capsules\n",
    "            x = tf.sqrt(tf.reduce_sum(tf.square(inputs), -1))\n",
    "            # generate the mask which is a one-hot code.\n",
    "            # mask.shape=[None, n_classes]=[None, num_capsule]\n",
    "            mask = tf.one_hot(indices=tf.argmax(x, 1), depth=x.shape[1])\n",
    "\n",
    "        # inputs.shape=[None, num_capsule, dim_capsule]\n",
    "        # mask.shape=[None, num_capsule]\n",
    "        # masked.shape=[None, num_capsule * dim_capsule]\n",
    "        masked = K.batch_flatten(inputs * tf.expand_dims(mask, -1))\n",
    "        return masked\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if type(input_shape[0]) is tuple:  # true label provided\n",
    "            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n",
    "        else:  # no true label provided\n",
    "            return tuple([None, input_shape[1] * input_shape[2]])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Mask, self).get_config()\n",
    "        return config\n",
    "\n",
    "\n",
    "def squash(vectors, axis=-1):\n",
    "    \"\"\"\n",
    "    The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n",
    "    :param vectors: some vectors to be squashed, N-dim tensor\n",
    "    :param axis: the axis to squash\n",
    "    :return: a Tensor with same shape as input vectors\n",
    "    \"\"\"\n",
    "    s_squared_norm = tf.reduce_sum(tf.square(vectors), axis, keepdims=True)\n",
    "    scale = s_squared_norm / (1 + s_squared_norm) / tf.sqrt(s_squared_norm + K.epsilon())\n",
    "    return scale * vectors\n",
    "\n",
    "\n",
    "class CapsuleLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    The capsule layer. It is similar to Dense layer. Dense layer has `in_num` inputs, each is a scalar, the output of the\n",
    "    neuron from the former layer, and it has `out_num` output neurons. CapsuleLayer just expand the output of the neuron\n",
    "    from scalar to vector. So its input shape = [None, input_num_capsule, input_dim_capsule] and output shape = \\\n",
    "    [None, num_capsule, dim_capsule]. For Dense Layer, input_dim_capsule = dim_capsule = 1.\n",
    "    :param num_capsule: number of capsules in this layer\n",
    "    :param dim_capsule: dimension of the output vectors of the capsules in this layer\n",
    "    :param routings: number of iterations for the routing algorithm\n",
    "    \"\"\"\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 **kwargs):\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_capsule]\"\n",
    "        self.input_num_capsule = input_shape[1]\n",
    "        self.input_dim_capsule = input_shape[2]\n",
    "\n",
    "        # Transform matrix, from each input capsule to each output capsule, there's a unique weight as in Dense layer.\n",
    "        self.W = self.add_weight(shape=[self.num_capsule, self.input_num_capsule,\n",
    "                                        self.dim_capsule, self.input_dim_capsule],\n",
    "                                 initializer=self.kernel_initializer,\n",
    "                                 name='W')\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # inputs.shape=[None, input_num_capsule, input_dim_capsule]\n",
    "        # inputs_expand.shape=[None, 1, input_num_capsule, input_dim_capsule, 1]\n",
    "        inputs_expand = tf.expand_dims(tf.expand_dims(inputs, 1), -1)\n",
    "\n",
    "        # Replicate num_capsule dimension to prepare being multiplied by W\n",
    "        # inputs_tiled.shape=[None, num_capsule, input_num_capsule, input_dim_capsule, 1]\n",
    "        inputs_tiled = tf.tile(inputs_expand, [1, self.num_capsule, 1, 1, 1])\n",
    "\n",
    "        # Compute `inputs * W` by scanning inputs_tiled on dimension 0.\n",
    "        # W.shape=[num_capsule, input_num_capsule, dim_capsule, input_dim_capsule]\n",
    "        # x.shape=[num_capsule, input_num_capsule, input_dim_capsule, 1]\n",
    "        # Regard the first two dimensions as `batch` dimension, then\n",
    "        # matmul(W, x): [..., dim_capsule, input_dim_capsule] x [..., input_dim_capsule, 1] -> [..., dim_capsule, 1].\n",
    "        # inputs_hat.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
    "        inputs_hat = tf.squeeze(tf.map_fn(lambda x: tf.matmul(self.W, x), elems=inputs_tiled))\n",
    "\n",
    "        # Begin: Routing algorithm ---------------------------------------------------------------------#\n",
    "        # The prior for coupling coefficient, initialized as zeros.\n",
    "        # b.shape = [None, self.num_capsule, 1, self.input_num_capsule].\n",
    "        batch_size = tf.shape(inputs)[0]  # ✅ Dynamically get batch size\n",
    "        b = tf.zeros(shape=[batch_size, self.num_capsule, 1, self.input_num_capsule])\n",
    "\n",
    "\n",
    "        assert self.routings > 0, 'The routings should be > 0.'\n",
    "        for i in range(self.routings):\n",
    "            # c.shape=[batch_size, num_capsule, 1, input_num_capsule]\n",
    "            c = tf.nn.softmax(b, axis=1)\n",
    "\n",
    "            # c.shape = [batch_size, num_capsule, 1, input_num_capsule]\n",
    "            # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
    "            # The first two dimensions as `batch` dimension,\n",
    "            # then matmal: [..., 1, input_num_capsule] x [..., input_num_capsule, dim_capsule] -> [..., 1, dim_capsule].\n",
    "            # outputs.shape=[None, num_capsule, 1, dim_capsule]\n",
    "            outputs = squash(tf.matmul(c, inputs_hat))  # [None, 10, 1, 16]\n",
    "\n",
    "            if i < self.routings - 1:\n",
    "                # outputs.shape =  [None, num_capsule, 1, dim_capsule]\n",
    "                # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
    "                # The first two dimensions as `batch` dimension, then\n",
    "                # matmal:[..., 1, dim_capsule] x [..., input_num_capsule, dim_capsule]^T -> [..., 1, input_num_capsule].\n",
    "                # b.shape=[batch_size, num_capsule, 1, input_num_capsule]\n",
    "                b += tf.matmul(outputs, inputs_hat, transpose_b=True)\n",
    "        # End: Routing algorithm -----------------------------------------------------------------------#\n",
    "\n",
    "        return tf.squeeze(outputs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple([None, self.num_capsule, self.dim_capsule])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'num_capsule': self.num_capsule,\n",
    "            'dim_capsule': self.dim_capsule,\n",
    "            'routings': self.routings\n",
    "        }\n",
    "        base_config = super(CapsuleLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
    "    \"\"\"\n",
    "    Apply Conv2D `n_channels` times and concatenate all capsules\n",
    "    :param inputs: 4D tensor, shape=[None, width, height, channels]\n",
    "    :param dim_capsule: the dim of the output vector of capsule\n",
    "    :param n_channels: the number of types of capsules\n",
    "    :return: output tensor, shape=[None, num_capsule, dim_capsule]\n",
    "    \"\"\"\n",
    "    output = layers.Conv2D(filters=dim_capsule*n_channels, kernel_size=kernel_size, strides=strides, padding=padding,\n",
    "                           name='primarycap_conv2d')(inputs)\n",
    "    outputs = layers.Reshape(target_shape=[-1, dim_capsule], name='primarycap_reshape')(output)\n",
    "    return layers.Lambda(squash, name='primarycap_squash')(outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# The following is another way to implement primary capsule layer. This is much slower.\n",
    "# Apply Conv2D `n_channels` times and concatenate all capsules\n",
    "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
    "    outputs = []\n",
    "    for _ in range(n_channels):\n",
    "        output = layers.Conv2D(filters=dim_capsule, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\n",
    "        outputs.append(layers.Reshape([output.get_shape().as_list()[1] ** 2, dim_capsule])(output))\n",
    "    outputs = layers.Concatenate(axis=1)(outputs)\n",
    "    return layers.Lambda(squash)(outputs)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "bc101123-d53c-4c2e-a187-101c434885da",
    "_uuid": "2497453eb1895f624ad84617dd98c230f5640304",
    "colab": {},
    "colab_type": "code",
    "id": "HCMIciV0o8x9"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "def CapsNet(input_shape, n_class, routings, batch_size):\n",
    "    \"\"\"\n",
    "    A Lightweight Capsule Network on MNIST.\n",
    "    \"\"\"\n",
    "    x = layers.Input(shape=input_shape, batch_size=batch_size)\n",
    "\n",
    "    # Reduced Conv2D filters\n",
    "    conv1 = layers.Conv2D(filters=128, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
    "\n",
    "    # Reduced primary capsules\n",
    "    primarycaps = PrimaryCap(conv1, dim_capsule=4, n_channels=16, kernel_size=9, strides=2, padding='valid')\n",
    "\n",
    "    # Reduced dimensions in DigitCaps layer\n",
    "    digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=8, routings=routings, name='digitcaps')(primarycaps)\n",
    "\n",
    "    # Capsule length layer\n",
    "    out_caps = Length(name='capsnet')(digitcaps)\n",
    "\n",
    "    # Decoder with reduced parameters\n",
    "    y = layers.Input(shape=(n_class,))\n",
    "    masked_by_y = Mask()([digitcaps, y])\n",
    "    masked = Mask()(digitcaps)\n",
    "\n",
    "    decoder = models.Sequential(name='decoder')\n",
    "    decoder.add(layers.Dense(256, activation='relu', input_dim=8 * n_class))\n",
    "    decoder.add(layers.Dense(512, activation='relu'))\n",
    "    decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
    "    decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
    "\n",
    "    # Models for training and evaluation\n",
    "    train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
    "    eval_model = models.Model(x, [out_caps, decoder(masked)])\n",
    "\n",
    "    # Manipulation model\n",
    "    noise = layers.Input(shape=(n_class, 8))\n",
    "    noised_digitcaps = layers.Add()([digitcaps, noise])\n",
    "    masked_noised_y = Mask()([noised_digitcaps, y])\n",
    "    manipulate_model = models.Model([x, y, noise], decoder(masked_noised_y))\n",
    "\n",
    "    return train_model, eval_model, manipulate_model\n",
    "\n",
    "# def CapsNet(input_shape, n_class, routings, batch_size):\n",
    "#     \"\"\"\n",
    "#     A Capsule Network on MNIST.\n",
    "#     :param input_shape: data shape, 3d, [width, height, channels]\n",
    "#     :param n_class: number of classes\n",
    "#     :param routings: number of routing iterations\n",
    "#     :param batch_size: size of batch\n",
    "#     :return: Two Keras Models, the first one used for training, and the second one for evaluation.\n",
    "#             `eval_model` can also be used for training.\n",
    "#     \"\"\"\n",
    "#     x = layers.Input(shape=input_shape, batch_size=batch_size)\n",
    "\n",
    "#     # Layer 1: Just a conventional Conv2D layer\n",
    "#     conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
    "\n",
    "#     # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
    "#     primarycaps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
    "\n",
    "#     # Layer 3: Capsule layer. Routing algorithm works here.\n",
    "#     digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings, name='digitcaps')(primarycaps)\n",
    "\n",
    "#     # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
    "#     # If using tensorflow, this will not be necessary. :)\n",
    "#     out_caps = Length(name='capsnet')(digitcaps)\n",
    "\n",
    "#     # Decoder network.\n",
    "#     y = layers.Input(shape=(n_class,))\n",
    "#     masked_by_y = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer. For training\n",
    "#     masked = Mask()(digitcaps)  # Mask using the capsule with maximal length. For prediction\n",
    "\n",
    "#     # Shared Decoder model in training and prediction\n",
    "#     decoder = models.Sequential(name='decoder')\n",
    "#     decoder.add(layers.Dense(512, activation='relu', input_dim=16 * n_class))\n",
    "#     decoder.add(layers.Dense(1024, activation='relu'))\n",
    "#     decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
    "#     decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
    "\n",
    "#     # Models for training and evaluation (prediction)\n",
    "#     train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
    "#     eval_model = models.Model(x, [out_caps, decoder(masked)])\n",
    "\n",
    "#     # manipulate model\n",
    "#     noise = layers.Input(shape=(n_class, 16))\n",
    "#     noised_digitcaps = layers.Add()([digitcaps, noise])\n",
    "#     masked_noised_y = Mask()([noised_digitcaps, y])\n",
    "#     manipulate_model = models.Model([x, y, noise], decoder(masked_noised_y))\n",
    "#     return train_model, eval_model, manipulate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "c6d84e5a-c33c-40c8-89c3-aba3454f7025",
    "_uuid": "9f27c6b0623ebffb6c8a24579f9dd4e321d6b1c2",
    "colab": {},
    "colab_type": "code",
    "id": "LS09Ic7qo8x_"
   },
   "outputs": [],
   "source": [
    "def margin_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
    "    :param y_true: [None, n_classes]\n",
    "    :param y_pred: [None, num_capsule]\n",
    "    :return: a scalar loss value.\n",
    "    \"\"\"\n",
    "    # return tf.reduce_mean(tf.square(y_pred))\n",
    "    L = y_true * tf.square(tf.maximum(0., 0.9 - y_pred)) + \\\n",
    "        0.5 * (1 - y_true) * tf.square(tf.maximum(0., y_pred - 0.1))\n",
    "\n",
    "    return tf.reduce_mean(tf.reduce_sum(L, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "6f168849-f8f9-4241-9ba8-59abc59573f1",
    "_uuid": "d21637e677fca5be415b2ff2e8a94ef7db2ea8a1",
    "colab": {},
    "colab_type": "code",
    "id": "oa3i75Dao8yC"
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "#(input_shape, n_class, routings, batch_size):\n",
    "#model = CapsNet(input_shape=[28, 28, 1],\n",
    "#                n_class=10,\n",
    "#                routings=3,batch_size=100)\n",
    "#model.summary()\n",
    "#try:\n",
    "#    plot_model(model, to_file='model.png', show_shapes=True)\n",
    "#except Exception as e:\n",
    "#    print('No fancy plot {}'.format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "169b7f78-12c7-4fed-886e-60024fe59339",
    "_uuid": "02b7db879a533e7bfb3116522bebf3867b23498c",
    "colab": {},
    "colab_type": "code",
    "id": "0zSuXAxxo8yQ"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import csv\n",
    "import math\n",
    "import pandas\n",
    "\n",
    "def combine_images(generated_images, height=None, width=None):\n",
    "    num = generated_images.shape[0]\n",
    "    if width is None and height is None:\n",
    "        width = int(math.sqrt(num))\n",
    "        height = int(math.ceil(float(num)/width))\n",
    "    elif width is not None and height is None:  # height not given\n",
    "        height = int(math.ceil(float(num)/width))\n",
    "    elif height is not None and width is None:  # width not given\n",
    "        width = int(math.ceil(float(num)/height))\n",
    "\n",
    "    shape = generated_images.shape[1:3]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[:, :, 0]\n",
    "    return image\n",
    "\n",
    "def plot_log(filename, show=True):\n",
    "\n",
    "    data = pandas.read_csv(filename)\n",
    "\n",
    "    fig = plt.figure(figsize=(4,6))\n",
    "    fig.subplots_adjust(top=0.95, bottom=0.05, right=0.95)\n",
    "    fig.add_subplot(211)\n",
    "    for key in data.keys():\n",
    "        if key.find('loss') >= 0 and not key.find('val') >= 0:  # training loss\n",
    "            plt.plot(data['epoch'].values, data[key].values, label=key)\n",
    "    plt.legend()\n",
    "    plt.title('Training loss')\n",
    "\n",
    "    fig.add_subplot(212)\n",
    "    for key in data.keys():\n",
    "        if key.find('acc') >= 0:  # acc\n",
    "            plt.plot(data['epoch'].values, data[key].values, label=key)\n",
    "    plt.legend()\n",
    "    plt.title('Training and validation accuracy')\n",
    "\n",
    "    # fig.savefig('result/log.png')\n",
    "    if show:\n",
    "        plt.show()    \n",
    "\n",
    "def test(model, data, args):\n",
    "    x_test, y_test = data\n",
    "    y_pred, x_recon = model.predict(x_test, batch_size=100)\n",
    "    print('-' * 30 + 'Begin: test' + '-' * 30)\n",
    "    print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1)) / y_test.shape[0])\n",
    "\n",
    "    img = combine_images(np.concatenate([x_test[:50], x_recon[:50]]))\n",
    "    image = img * 255\n",
    "    Image.fromarray(image.astype(np.uint8)).save(args.save_dir + \"/real_and_recon.png\")\n",
    "    print()\n",
    "    print('Reconstructed images are saved to %s/real_and_recon.png' % args.save_dir)\n",
    "    print('-' * 30 + 'End: test' + '-' * 30)\n",
    "    plt.imshow(plt.imread(args.save_dir + \"/real_and_recon.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "e698ab37-4e74-43e6-b35b-a0507449d916",
    "_uuid": "c0374dabdf452026e3f231ffe689b5dd9f99288b",
    "colab": {},
    "colab_type": "code",
    "id": "TZJyVmido8yK"
   },
   "outputs": [],
   "source": [
    "def train(model, data, args):\n",
    "    \"\"\"\n",
    "    Training a CapsuleNet\n",
    "    :param model: the CapsuleNet model\n",
    "    :param data: a tuple containing training and testing data, like `((x_train, y_train), (x_test, y_test))`\n",
    "    :param args: arguments\n",
    "    :return: The trained model\n",
    "    \"\"\"\n",
    "    # unpacking the data\n",
    "    (x_train, y_train), (x_test, y_test) = data\n",
    "\n",
    "    # callbacks\n",
    "    log = callbacks.CSVLogger(args.save_dir + '/log.csv')\n",
    "    checkpoint = callbacks.ModelCheckpoint(args.save_dir + '/model-{epoch:02d}.keras', \n",
    "                                       monitor='val_capsnet_accuracy',\n",
    "                                       save_best_only=True, \n",
    "                                       save_weights_only=False,  # ✅ Save the full model\n",
    "                                       verbose=1)\n",
    "\n",
    "    lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: args.lr * (args.lr_decay ** epoch))\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=args.lr),  # ✅ Use 'learning_rate'\n",
    "                  loss=[margin_loss, 'mse'],\n",
    "                  loss_weights=[1., args.lam_recon],\n",
    "                  metrics={'capsnet': 'accuracy'})\n",
    "\n",
    "    \"\"\"\n",
    "    # Training without data augmentation:\n",
    "    model.fit([x_train, y_train], [y_train, x_train], batch_size=args.batch_size, epochs=args.epochs,\n",
    "              validation_data=[[x_test, y_test], [y_test, x_test]], callbacks=[log, tb, checkpoint, lr_decay])\n",
    "    \"\"\"\n",
    "\n",
    "    # Begin: Training with data augmentation ---------------------------------------------------------------------#\n",
    "    def train_generator(x, y, batch_size, shift_fraction=0.):\n",
    "        train_datagen = ImageDataGenerator(width_shift_range=shift_fraction,\n",
    "                                           height_shift_range=shift_fraction)  # shift up to 2 pixels\n",
    "        generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
    "        while True:  # Infinite loop for data generation\n",
    "            x_batch, y_batch = next(generator)  # ✅ Corrected line\n",
    "            yield (x_batch, y_batch), (y_batch, x_batch)\n",
    "\n",
    "\n",
    "    # Training with data augmentation. If shift_fraction=0., no augmentation.\n",
    "    model.fit(train_generator(x_train, y_train, args.batch_size, args.shift_fraction),\n",
    "              steps_per_epoch=int(y_train.shape[0] / args.batch_size),\n",
    "              epochs=args.epochs,\n",
    "              validation_data=((x_test, y_test), (y_test, x_test)), batch_size=args.batch_size,\n",
    "              callbacks=[log, checkpoint, lr_decay])\n",
    "        \n",
    "    # End: Training with data augmentation -----------------------------------------------------------------------#\n",
    "    # Save the full model in Keras format\n",
    "    model.save(args.save_dir + '/full_trained_model.keras')\n",
    "    print(f'Full trained model saved to {args.save_dir}/full_trained_model.keras')\n",
    "    \n",
    "    # Save the full model in HDF5 format (if needed)\n",
    "    model.save(args.save_dir + '/full_trained_model.h5')\n",
    "    print(f'Full trained model saved to {args.save_dir}/full_trained_model.h5')\n",
    "    \n",
    "    # Save only the weights\n",
    "    model.save_weights(args.save_dir + '/trained_model.weights.h5')\n",
    "    print(f'Trained model weights saved to {args.save_dir}/trained_model.weights.h5')\n",
    "\n",
    "\n",
    "    plot_log(args.save_dir + '/log.csv', show=True)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_EKbfeEhiYkr",
    "outputId": "2c7bb18a-fcdc-44c1-8d91-2ae9be8488f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(epochs=10, batch_size=32, lr=0.001, lr_decay=0.9, lam_recon=0.392, routings=1, shift_fraction=0.1, debug=False, save_dir='./result', testing=False, digit=5, weights=None)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Capsule Network on MNIST.\")\n",
    "parser.add_argument('--epochs', default=10, type=int)\n",
    "parser.add_argument('--batch_size', default=32, type=int)\n",
    "parser.add_argument('--lr', default=0.001, type=float,\n",
    "                        help=\"Initial learning rate\")\n",
    "parser.add_argument('--lr_decay', default=0.9, type=float,\n",
    "                        help=\"The value multiplied by lr at each epoch. Set a larger value for larger epochs\")\n",
    "parser.add_argument('--lam_recon', default=0.392, type=float,\n",
    "                        help=\"The coefficient for the loss of decoder\")\n",
    "parser.add_argument('-r', '--routings', default=1, type=int,\n",
    "                        help=\"Number of iterations used in routing algorithm. should > 0\")\n",
    "parser.add_argument('--shift_fraction', default=0.1, type=float,\n",
    "                        help=\"Fraction of pixels to shift at most in each direction.\")\n",
    "parser.add_argument('--debug', action='store_true',\n",
    "                        help=\"Save weights by TensorBoard\")\n",
    "parser.add_argument('--save_dir', default='./result')\n",
    "parser.add_argument('-t', '--testing', action='store_true',\n",
    "                        help=\"Test the trained model on testing dataset\")\n",
    "parser.add_argument('--digit', default=5, type=int,\n",
    "                        help=\"Digit to manipulate\")\n",
    "parser.add_argument('-w', '--weights', default=None,\n",
    "                        help=\"The path of the saved weights. Should be specified when testing\")\n",
    "args, unknown = parser.parse_known_args()\n",
    "print(args)\n",
    "\n",
    "if not os.path.exists(args.save_dir):\n",
    "    os.makedirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "9dbcd67c-8f99-4d8b-8cf7-480d8dc069a4",
    "_uuid": "526436cc40013621251285812ba95725d4a6d749",
    "colab": {},
    "colab_type": "code",
    "id": "7UfmktlEo8yF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "def load_drowsy_dataset(data_dir):\n",
    "    # Load train and test datasets using image_dataset_from_directory\n",
    "    train_dataset = image_dataset_from_directory(\n",
    "        os.path.join(data_dir, 'train'),\n",
    "        image_size=(128, 128),  # Resize images to 128x128\n",
    "        batch_size=32,  # Adjust as needed\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    test_dataset = image_dataset_from_directory(\n",
    "        os.path.join(data_dir, 'test'),\n",
    "        image_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Get class names before mapping\n",
    "    class_names = train_dataset.class_names\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    # Normalize images\n",
    "    train_dataset = train_dataset.map(lambda x, y: (x / 255.0, y))\n",
    "    test_dataset = test_dataset.map(lambda x, y: (x / 255.0, y))\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    def one_hot_encode(y):\n",
    "        return tf.one_hot(y, depth=num_classes)\n",
    "\n",
    "    train_dataset = train_dataset.map(lambda x, y: (x, one_hot_encode(y)))\n",
    "    test_dataset = test_dataset.map(lambda x, y: (x, one_hot_encode(y)))\n",
    "\n",
    "    return train_dataset, test_dataset, class_names  # Returning class_names for reference\n",
    "\n",
    "# Example usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "id": "l-i3c_UESE2P",
    "outputId": "dedac7c8-475a-41ff-c571-39dd3a4d5419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11271 files belonging to 2 classes.\n",
      "Found 2819 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    " # load data\n",
    "data_dir = r\"D:\\Major Project\\Rasp\\Data\"\n",
    "train_dataset, test_dataset, class_names = load_drowsy_dataset(data_dir)\n",
    "\n",
    "# Extract x_train and y_train from the train_dataset\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for x, y in train_dataset:\n",
    "    x_train.append(x.numpy())  # Convert the tensor to a NumPy array\n",
    "    y_train.append(y.numpy())  # Convert the tensor to a NumPy array\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "x_train = np.concatenate(x_train, axis=0)\n",
    "y_train = np.concatenate(y_train, axis=0)\n",
    "# Now you have x_train and y_train as NumPy arrays\n",
    "\n",
    "# Extract x_test and y_test from the test_dataset\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for x, y in test_dataset:\n",
    "    x_test.append(x.numpy())  # Convert the tensor to a NumPy array\n",
    "    y_test.append(y.numpy())  # Convert the tensor to a NumPy array\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "x_test = np.concatenate(x_test, axis=0)\n",
    "y_test = np.concatenate(y_test, axis=0)\n",
    "# Now you have x_test and y_test as NumPy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "id": "l-i3c_UESE2P",
    "outputId": "dedac7c8-475a-41ff-c571-39dd3a4d5419"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">31,232</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ primarycap_conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">663,616</span> │ conv1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ primarycap_reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ primarycap_conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ primarycap_squash (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ primarycap_reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ digitcaps (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CapsuleLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,211,264</span> │ primarycap_squash[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ mask_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Mask</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ digitcaps[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ capsnet (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Length</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ digitcaps[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">25,350,912</span> │ mask_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m31,232\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ primarycap_conv2d (\u001b[38;5;33mConv2D\u001b[0m)    │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m663,616\u001b[0m │ conv1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ primarycap_reshape (\u001b[38;5;33mReshape\u001b[0m)  │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m50176\u001b[0m, \u001b[38;5;34m4\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ primarycap_conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ primarycap_squash (\u001b[38;5;33mLambda\u001b[0m)    │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m50176\u001b[0m, \u001b[38;5;34m4\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ primarycap_reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ digitcaps (\u001b[38;5;33mCapsuleLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │       \u001b[38;5;34m3,211,264\u001b[0m │ primarycap_squash[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ mask_3 (\u001b[38;5;33mMask\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ digitcaps[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ input_layer_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ capsnet (\u001b[38;5;33mLength\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ digitcaps[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder (\u001b[38;5;33mSequential\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)       │      \u001b[38;5;34m25,350,912\u001b[0m │ mask_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,257,024</span> (111.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,257,024\u001b[0m (111.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,257,024</span> (111.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,257,024\u001b[0m (111.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_classes = y_train.shape[1]\n",
    "model, eval_model, manipulate_model = CapsNet(input_shape=x_train.shape[1:],\n",
    "                                               n_class=num_classes,\n",
    "                                               routings=args.routings,\n",
    "                                               batch_size=args.batch_size)\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "2fda2834-7c9e-4ed6-b322-0b9e86415201",
    "_uuid": "07bbb33aaa1c7ec875798359e300bbcdba374659",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8NCOZGHlo8yM",
    "outputId": "2293c1b5-bde2-45aa-ae80-b3bd45b186a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling CapsuleLayer.call().\n\n\u001b[1mExpected int32, but got None of type 'NoneType'.\u001b[0m\n\nArguments received by CapsuleLayer.call():\n  • inputs=tf.Tensor(shape=(None, 50176, 4), dtype=float32)\n  • training=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#train(model=model, data=((x_train, y_train), (x_test[:60], y_test[:60])), \u001b[39;00m\n\u001b[0;32m      2\u001b[0m  \u001b[38;5;66;03m#     epoch_size_frac = 0.5) # do 10% of an epoch (takes too long)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 45\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, data, args)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m (x_batch, y_batch), (y_batch, x_batch)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Training with data augmentation. If shift_fraction=0., no augmentation.\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshift_fraction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m          \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_decay\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# End: Training with data augmentation -----------------------------------------------------------------------#\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Save the full model in Keras format\u001b[39;00m\n\u001b[0;32m     53\u001b[0m model\u001b[38;5;241m.\u001b[39msave(args\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/full_trained_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\Major Project\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[2], line 129\u001b[0m, in \u001b[0;36mCapsuleLayer.call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    124\u001b[0m inputs_hat \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msqueeze(tf\u001b[38;5;241m.\u001b[39mmap_fn(\u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mmatmul(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW, x), elems\u001b[38;5;241m=\u001b[39minputs_tiled))\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# Begin: Routing algorithm ---------------------------------------------------------------------#\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# The prior for coupling coefficient, initialized as zeros.\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# b.shape = [None, self.num_capsule, 1, self.input_num_capsule].\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_capsule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_num_capsule\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroutings \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe routings should be > 0.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroutings):\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# c.shape=[batch_size, num_capsule, 1, input_num_capsule]\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: Exception encountered when calling CapsuleLayer.call().\n\n\u001b[1mExpected int32, but got None of type 'NoneType'.\u001b[0m\n\nArguments received by CapsuleLayer.call():\n  • inputs=tf.Tensor(shape=(None, 50176, 4), dtype=float32)\n  • training=True"
     ]
    }
   ],
   "source": [
    "#train(model=model, data=((x_train, y_train), (x_test[:60], y_test[:60])), \n",
    " #     epoch_size_frac = 0.5) # do 10% of an epoch (takes too long)\n",
    "train(model=model, data=((x_train, y_train), (x_test, y_test)), args=args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2706080d-2d50-4876-bd4d-c0f3c4ce87b5",
    "_uuid": "9afcde53f3cf3ba3eeeed1f083241874b4cd84e2",
    "colab_type": "text",
    "id": "lMRMqKA9o8yS"
   },
   "source": [
    "# Show the results on the hold-out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "56a6fe58-fe97-45c8-95da-223297842f79",
    "_uuid": "25ac7feb2d111b82e755169288ffd47ebc4d196a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "colab_type": "code",
    "id": "PL8it8clo8yT",
    "outputId": "e65e69e0-03f2-49bf-efbc-ec13927ec499"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test(model=eval_model, data=(x_test, y_test), args=args)\n",
    "#test(model=model, data=(x_test[:100], y_test[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xiBpPdkmY500"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CapsuleNet on MNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
