{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "812d170b-bb78-469e-9423-c4923461c25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define dataset paths\n",
    "dataset_path = \"D:/Major Project/Final Proper/Dataset\"\n",
    "output_path = \"D:/Major Project/Final Proper/Split_Dataset\"\n",
    "\n",
    "american_path = os.path.join(dataset_path, \"American\")\n",
    "chinese_path = os.path.join(dataset_path, \"Chinese\")\n",
    "\n",
    "# Define clients\n",
    "clients = {\n",
    "    \"C1\": {\"Chinese\": 0.8, \"American\": 0.2},\n",
    "    \"C2\": {\"Chinese\": 0.2, \"American\": 0.8},\n",
    "}\n",
    "\n",
    "# Categories\n",
    "categories = [\"Drowsy\", \"NonDrowsy\"]\n",
    "\n",
    "# Function to split and copy data\n",
    "def split_data(source_path, dest_path, split_ratio):\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(source_path, category)\n",
    "        dest_category_path = os.path.join(dest_path, category)\n",
    "        os.makedirs(dest_category_path, exist_ok=True)\n",
    "\n",
    "        files = os.listdir(category_path)\n",
    "        random.shuffle(files)\n",
    "        split_count = int(len(files) * split_ratio)\n",
    "\n",
    "        for file in files[:split_count]:\n",
    "            shutil.copy(os.path.join(category_path, file), os.path.join(dest_category_path, file))\n",
    "\n",
    "# Processing clients\n",
    "for client, proportions in clients.items():\n",
    "    client_path = os.path.join(output_path, client)\n",
    "    \n",
    "    # Split American data\n",
    "    split_data(american_path, client_path, proportions[\"American\"])\n",
    "    \n",
    "    # Split Chinese data\n",
    "    split_data(chinese_path, client_path, proportions[\"Chinese\"])\n",
    "\n",
    "print(\"Dataset split completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33200b7b-8d1f-4ace-8897-b1cf451b39de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing C1...\n",
      "  Round 1: Drowsy - 600 Chinese, 400 American\n",
      "  Round 1: NonDrowsy - 600 Chinese, 400 American\n",
      "  Round 2: Drowsy - 600 Chinese, 400 American\n",
      "  Round 2: NonDrowsy - 600 Chinese, 400 American\n",
      "  Round 3: Drowsy - 600 Chinese, 400 American\n",
      "  Round 3: NonDrowsy - 600 Chinese, 400 American\n",
      "  Round 4: Drowsy - 600 Chinese, 400 American\n",
      "  Round 4: NonDrowsy - 600 Chinese, 400 American\n",
      "  Round 5: Drowsy - 600 Chinese, 400 American\n",
      "  Round 5: NonDrowsy - 600 Chinese, 400 American\n",
      "\n",
      "Processing C2...\n",
      "  Round 1: Drowsy - 400 Chinese, 600 American\n",
      "  Round 1: NonDrowsy - 400 Chinese, 600 American\n",
      "  Round 2: Drowsy - 400 Chinese, 600 American\n",
      "  Round 2: NonDrowsy - 400 Chinese, 600 American\n",
      "  Round 3: Drowsy - 400 Chinese, 600 American\n",
      "  Round 3: NonDrowsy - 400 Chinese, 600 American\n",
      "  Round 4: Drowsy - 400 Chinese, 600 American\n",
      "  Round 4: NonDrowsy - 400 Chinese, 600 American\n",
      "  Round 5: Drowsy - 400 Chinese, 600 American\n",
      "  Round 5: NonDrowsy - 400 Chinese, 600 American\n",
      "✅ Dataset successfully split into 5 rounds with proper shuffling and correct proportions!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define dataset paths\n",
    "dataset_path = \"D:/Major Project/Final Proper/Dataset\"\n",
    "output_path = \"D:/Major Project/Final Proper/Split_Dataset_with_rounds\"\n",
    "\n",
    "american_path = os.path.join(dataset_path, \"American\")\n",
    "chinese_path = os.path.join(dataset_path, \"Chinese\")\n",
    "\n",
    "# Define clients and proportions\n",
    "clients = {\n",
    "    \"C1\": {\"Chinese\": 0.6, \"American\": 0.4},\n",
    "    \"C2\": {\"Chinese\": 0.4, \"American\": 0.6},\n",
    "}\n",
    "\n",
    "# Categories (classes)\n",
    "categories = [\"Drowsy\", \"NonDrowsy\"]\n",
    "\n",
    "# Define dataset size per round\n",
    "per_class_size = 1000  # Each round has 1000 Drowsy + 1000 Non-Drowsy = 2000 total\n",
    "rounds = 5  # Number of rounds\n",
    "\n",
    "# Function to shuffle and split data\n",
    "def prepare_shuffled_data(source_path):\n",
    "    shuffled_data = {}\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(source_path, category)\n",
    "        files = os.listdir(category_path)\n",
    "        random.shuffle(files)  # Shuffle once at the start\n",
    "        shuffled_data[category] = files  # Store shuffled files\n",
    "    return shuffled_data\n",
    "\n",
    "# Process each client\n",
    "for client, proportions in clients.items():\n",
    "    print(f\"\\nProcessing {client}...\")\n",
    "    client_base_path = os.path.join(output_path, client)\n",
    "\n",
    "    # Prepare shuffled data\n",
    "    shuffled_american = prepare_shuffled_data(american_path)\n",
    "    shuffled_chinese = prepare_shuffled_data(chinese_path)\n",
    "\n",
    "    # Track indices for splitting\n",
    "    index_tracker = {category: {\"Chinese\": 0, \"American\": 0} for category in categories}\n",
    "\n",
    "    for round_num in range(1, rounds + 1):\n",
    "        round_path = os.path.join(client_base_path, f\"Round_{round_num}\")\n",
    "        os.makedirs(round_path, exist_ok=True)\n",
    "\n",
    "        for category in categories:\n",
    "            # Compute correct proportions\n",
    "            split_chinese = int(per_class_size * proportions[\"Chinese\"])\n",
    "            split_american = int(per_class_size * proportions[\"American\"])\n",
    "\n",
    "            # Get available images\n",
    "            remaining_chinese = len(shuffled_chinese[category]) - index_tracker[category][\"Chinese\"]\n",
    "            remaining_american = len(shuffled_american[category]) - index_tracker[category][\"American\"]\n",
    "\n",
    "            # Ensure we don't exceed available images\n",
    "            split_chinese = min(split_chinese, remaining_chinese)\n",
    "            split_american = min(split_american, remaining_american)\n",
    "\n",
    "            # Get image subsets\n",
    "            start_c = index_tracker[category][\"Chinese\"]\n",
    "            end_c = start_c + split_chinese\n",
    "            start_a = index_tracker[category][\"American\"]\n",
    "            end_a = start_a + split_american\n",
    "\n",
    "            round_chinese = shuffled_chinese[category][start_c:end_c]\n",
    "            round_american = shuffled_american[category][start_a:end_a]\n",
    "\n",
    "            # Update index tracker\n",
    "            index_tracker[category][\"Chinese\"] = end_c\n",
    "            index_tracker[category][\"American\"] = end_a\n",
    "\n",
    "            # Copy files to destination\n",
    "            dest_category_path = os.path.join(round_path, category)\n",
    "            os.makedirs(dest_category_path, exist_ok=True)\n",
    "\n",
    "            for file in round_chinese:\n",
    "                shutil.copy(os.path.join(chinese_path, category, file), os.path.join(dest_category_path, file))\n",
    "\n",
    "            for file in round_american:\n",
    "                shutil.copy(os.path.join(american_path, category, file), os.path.join(dest_category_path, file))\n",
    "\n",
    "            print(f\"  Round {round_num}: {category} - {len(round_chinese)} Chinese, {len(round_american)} American\")\n",
    "\n",
    "        # Warn if we ran out of images\n",
    "        if index_tracker[\"Drowsy\"][\"Chinese\"] >= len(shuffled_chinese[\"Drowsy\"]) or index_tracker[\"Drowsy\"][\"American\"] >= len(shuffled_american[\"Drowsy\"]):\n",
    "            print(f\"⚠️ WARNING: Not enough images left for further rounds after Round {round_num}. Stopping early!\")\n",
    "            break\n",
    "\n",
    "print(\"✅ Dataset successfully split into 5 rounds with proper shuffling and correct proportions!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c2d6e1e-5d10-4561-8b23-ad7489262a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing C1...\n",
      "  Round 1: Drowsy - 400 Chinese, 100 American\n",
      "  Round 1: NonDrowsy - 400 Chinese, 100 American\n",
      "  Round 2: Drowsy - 400 Chinese, 100 American\n",
      "  Round 2: NonDrowsy - 400 Chinese, 100 American\n",
      "  Round 3: Drowsy - 400 Chinese, 100 American\n",
      "  Round 3: NonDrowsy - 400 Chinese, 100 American\n",
      "  Round 4: Drowsy - 400 Chinese, 100 American\n",
      "  Round 4: NonDrowsy - 400 Chinese, 100 American\n",
      "  Round 5: Drowsy - 400 Chinese, 100 American\n",
      "  Round 5: NonDrowsy - 400 Chinese, 100 American\n",
      "\n",
      "Processing C2...\n",
      "  Round 1: Drowsy - 100 Chinese, 400 American\n",
      "  Round 1: NonDrowsy - 100 Chinese, 400 American\n",
      "  Round 2: Drowsy - 100 Chinese, 400 American\n",
      "  Round 2: NonDrowsy - 100 Chinese, 400 American\n",
      "  Round 3: Drowsy - 100 Chinese, 400 American\n",
      "  Round 3: NonDrowsy - 100 Chinese, 400 American\n",
      "  Round 4: Drowsy - 100 Chinese, 400 American\n",
      "  Round 4: NonDrowsy - 100 Chinese, 400 American\n",
      "  Round 5: Drowsy - 100 Chinese, 400 American\n",
      "  Round 5: NonDrowsy - 100 Chinese, 400 American\n",
      "✅ Dataset successfully split into 5 rounds using only 10,000 images!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define dataset paths\n",
    "dataset_path = \"D:/Major Project/Final Proper/Dataset\"\n",
    "output_path = \"D:/Major Project/Final Proper/Split_Dataset_with_rounds\"\n",
    "\n",
    "american_path = os.path.join(dataset_path, \"American\")\n",
    "chinese_path = os.path.join(dataset_path, \"Chinese\")\n",
    "\n",
    "# Define clients and their data proportions\n",
    "clients = {\n",
    "    \"C1\": {\"Chinese\": 0.6, \"American\": 0.4},\n",
    "    \"C2\": {\"Chinese\": 0.4, \"American\": 0.6},\n",
    "}\n",
    "\n",
    "# Categories (classes)\n",
    "categories = [\"Drowsy\", \"NonDrowsy\"]\n",
    "\n",
    "# Define dataset constraints\n",
    "total_images = 5000  # Use only 5,000 images (ignoring extra)\n",
    "per_class_total = total_images // 2  # 2,500 Drowsy + 2,500 Non-Drowsy\n",
    "per_round = per_class_total // 5  # 500 Drowsy + 500 Non-Drowsy total per round\n",
    "per_category_per_round = per_round // 2  # 250 per class (Drowsy/Non-Drowsy) per round\n",
    "\n",
    "# Function to get a limited, shuffled subset of images\n",
    "def get_limited_shuffled_data(source_path):\n",
    "    shuffled_data = {}\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(source_path, category)\n",
    "        files = os.listdir(category_path)\n",
    "        random.shuffle(files)  # Shuffle at start\n",
    "        shuffled_data[category] = files[:per_class_total]  # Take only 2,500 images\n",
    "    return shuffled_data\n",
    "\n",
    "# Process each client\n",
    "for client, proportions in clients.items():\n",
    "    print(f\"\\nProcessing {client}...\")\n",
    "    client_base_path = os.path.join(output_path, client)\n",
    "\n",
    "    # Prepare shuffled data (limited to 5,000 total)\n",
    "    shuffled_american = get_limited_shuffled_data(american_path)\n",
    "    shuffled_chinese = get_limited_shuffled_data(chinese_path)\n",
    "\n",
    "    # Track indices for splitting\n",
    "    index_tracker = {category: {\"Chinese\": 0, \"American\": 0} for category in categories}\n",
    "\n",
    "    for round_num in range(1, 6):  # 5 rounds\n",
    "        round_path = os.path.join(client_base_path, f\"Round_{round_num}\")\n",
    "        os.makedirs(round_path, exist_ok=True)\n",
    "\n",
    "        for category in categories:\n",
    "            # Compute correct proportions for each class\n",
    "            split_chinese = int(per_category_per_round * proportions[\"Chinese\"])\n",
    "            split_american = int(per_category_per_round * proportions[\"American\"])\n",
    "\n",
    "            # Get available images\n",
    "            start_c = index_tracker[category][\"Chinese\"]\n",
    "            end_c = start_c + split_chinese\n",
    "            start_a = index_tracker[category][\"American\"]\n",
    "            end_a = start_a + split_american\n",
    "\n",
    "            round_chinese = shuffled_chinese[category][start_c:end_c]\n",
    "            round_american = shuffled_american[category][start_a:end_a]\n",
    "\n",
    "            # Update index tracker\n",
    "            index_tracker[category][\"Chinese\"] = end_c\n",
    "            index_tracker[category][\"American\"] = end_a\n",
    "\n",
    "            # Copy files to destination\n",
    "            dest_category_path = os.path.join(round_path, category)\n",
    "            os.makedirs(dest_category_path, exist_ok=True)\n",
    "\n",
    "            for file in round_chinese:\n",
    "                shutil.copy(os.path.join(chinese_path, category, file), os.path.join(dest_category_path, file))\n",
    "\n",
    "            for file in round_american:\n",
    "                shutil.copy(os.path.join(american_path, category, file), os.path.join(dest_category_path, file))\n",
    "\n",
    "            print(f\"  Round {round_num}: {category} - {len(round_chinese)} Chinese, {len(round_american)} American\")\n",
    "\n",
    "print(\"✅ Dataset successfully split into 5 rounds using only 5,000 images!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a2b93fe-db34-44af-b42f-c33b74c77137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing C1 (Training)...\n",
      "  Round 1: Drowsy - 150 Chinese, 100 American\n",
      "  Round 1: NonDrowsy - 150 Chinese, 100 American\n",
      "  Round 2: Drowsy - 150 Chinese, 100 American\n",
      "  Round 2: NonDrowsy - 150 Chinese, 100 American\n",
      "  Round 3: Drowsy - 150 Chinese, 100 American\n",
      "  Round 3: NonDrowsy - 150 Chinese, 100 American\n",
      "  Round 4: Drowsy - 150 Chinese, 100 American\n",
      "  Round 4: NonDrowsy - 150 Chinese, 100 American\n",
      "  Round 5: Drowsy - 150 Chinese, 100 American\n",
      "  Round 5: NonDrowsy - 150 Chinese, 100 American\n",
      "\n",
      "Processing C2 (Training)...\n",
      "  Round 1: Drowsy - 100 Chinese, 150 American\n",
      "  Round 1: NonDrowsy - 100 Chinese, 150 American\n",
      "  Round 2: Drowsy - 100 Chinese, 150 American\n",
      "  Round 2: NonDrowsy - 100 Chinese, 150 American\n",
      "  Round 3: Drowsy - 100 Chinese, 150 American\n",
      "  Round 3: NonDrowsy - 100 Chinese, 150 American\n",
      "  Round 4: Drowsy - 100 Chinese, 150 American\n",
      "  Round 4: NonDrowsy - 100 Chinese, 150 American\n",
      "  Round 5: Drowsy - 100 Chinese, 150 American\n",
      "  Round 5: NonDrowsy - 100 Chinese, 150 American\n",
      "\n",
      "Processing Test Set...\n",
      "  Test Set: Drowsy - 2500 Chinese, 2500 American\n",
      "  Test Set: NonDrowsy - 2500 Chinese, 2500 American\n",
      "✅ Dataset successfully split into 5 training rounds and 1 test set!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define dataset paths\n",
    "dataset_path = \"D:/Major Project/Final Proper/Dataset\"\n",
    "output_path = \"D:/Major Project/Final Proper/Split_Dataset_with_rounds_with_test\"\n",
    "test_output_path = os.path.join(output_path, \"Test_Set\")\n",
    "\n",
    "american_path = os.path.join(dataset_path, \"American\")\n",
    "chinese_path = os.path.join(dataset_path, \"Chinese\")\n",
    "\n",
    "# Define clients and their data proportions\n",
    "clients = {\n",
    "    \"C1\": {\"Chinese\": 0.6, \"American\": 0.4},\n",
    "    \"C2\": {\"Chinese\": 0.4, \"American\": 0.6},\n",
    "}\n",
    "\n",
    "# Categories (classes)\n",
    "categories = [\"Drowsy\", \"NonDrowsy\"]\n",
    "\n",
    "# Define dataset constraints\n",
    "total_images = 10000  # Total dataset size\n",
    "train_size = total_images // 2  # 5,000 for training (split across 5 rounds)\n",
    "test_size = total_images // 2  # 5,000 for testing (fixed)\n",
    "\n",
    "per_class_train = train_size // 2  # 2,500 Drowsy + 2,500 Non-Drowsy for training\n",
    "per_class_test = test_size // 2  # 2,500 Drowsy + 2,500 Non-Drowsy for testing\n",
    "\n",
    "per_round_train = per_class_train // 5  # 500 total per round\n",
    "per_category_per_round = per_round_train // 2  # 250 per class per round\n",
    "\n",
    "# Function to get a limited, shuffled subset of images\n",
    "def get_limited_shuffled_data(source_path, limit):\n",
    "    shuffled_data = {}\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(source_path, category)\n",
    "        files = os.listdir(category_path)\n",
    "        random.shuffle(files)  # Shuffle at start\n",
    "        shuffled_data[category] = files[:limit]  # Take only `limit` images\n",
    "    return shuffled_data\n",
    "\n",
    "# Prepare shuffled data (split into training and testing)\n",
    "shuffled_american = get_limited_shuffled_data(american_path, total_images // 2)\n",
    "shuffled_chinese = get_limited_shuffled_data(chinese_path, total_images // 2)\n",
    "\n",
    "# Separate test data from train data\n",
    "test_american = {category: shuffled_american[category][per_class_train:] for category in categories}\n",
    "test_chinese = {category: shuffled_chinese[category][per_class_train:] for category in categories}\n",
    "\n",
    "# Track indices for splitting training data\n",
    "index_tracker = {category: {\"Chinese\": 0, \"American\": 0} for category in categories}\n",
    "\n",
    "# Process each client (Training Data)\n",
    "for client, proportions in clients.items():\n",
    "    print(f\"\\nProcessing {client} (Training)...\")\n",
    "    client_base_path = os.path.join(output_path, client)\n",
    "\n",
    "    for round_num in range(1, 6):  # 5 rounds\n",
    "        round_path = os.path.join(client_base_path, f\"Round_{round_num}\")\n",
    "        os.makedirs(round_path, exist_ok=True)\n",
    "\n",
    "        for category in categories:\n",
    "            # Compute correct proportions for each class\n",
    "            split_chinese = int(per_category_per_round * proportions[\"Chinese\"])\n",
    "            split_american = int(per_category_per_round * proportions[\"American\"])\n",
    "\n",
    "            # Get available images\n",
    "            start_c = index_tracker[category][\"Chinese\"]\n",
    "            end_c = start_c + split_chinese\n",
    "            start_a = index_tracker[category][\"American\"]\n",
    "            end_a = start_a + split_american\n",
    "\n",
    "            round_chinese = shuffled_chinese[category][start_c:end_c]\n",
    "            round_american = shuffled_american[category][start_a:end_a]\n",
    "\n",
    "            # Update index tracker\n",
    "            index_tracker[category][\"Chinese\"] = end_c\n",
    "            index_tracker[category][\"American\"] = end_a\n",
    "\n",
    "            # Copy files to destination\n",
    "            dest_category_path = os.path.join(round_path, category)\n",
    "            os.makedirs(dest_category_path, exist_ok=True)\n",
    "\n",
    "            for file in round_chinese:\n",
    "                shutil.copy(os.path.join(chinese_path, category, file), os.path.join(dest_category_path, file))\n",
    "\n",
    "            for file in round_american:\n",
    "                shutil.copy(os.path.join(american_path, category, file), os.path.join(dest_category_path, file))\n",
    "\n",
    "            print(f\"  Round {round_num}: {category} - {len(round_chinese)} Chinese, {len(round_american)} American\")\n",
    "\n",
    "# Process Testing Data (Remaining 5,000 images)\n",
    "print(\"\\nProcessing Test Set...\")\n",
    "for category in categories:\n",
    "    test_category_path = os.path.join(test_output_path, category)\n",
    "    os.makedirs(test_category_path, exist_ok=True)\n",
    "\n",
    "    # Copy test images\n",
    "    for file in test_chinese[category]:\n",
    "        shutil.copy(os.path.join(chinese_path, category, file), os.path.join(test_category_path, file))\n",
    "\n",
    "    for file in test_american[category]:\n",
    "        shutil.copy(os.path.join(american_path, category, file), os.path.join(test_category_path, file))\n",
    "\n",
    "    print(f\"  Test Set: {category} - {len(test_chinese[category])} Chinese, {len(test_american[category])} American\")\n",
    "\n",
    "print(\"✅ Dataset successfully split into 5 training rounds and 1 test set!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e2b0a-6b9b-4b8a-b939-2493ac871a50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
