{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a9e284-3c6c-41b6-bc23-4f13552545a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import struct\n",
    "import zlib\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "from tensorflow.keras import layers, initializers, backend as K\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import base64\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dee4cc15-4e87-4afa-9846-9fb4600914df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Capsule Network Components\n",
    "@register_keras_serializable(package=\"Custom\")\n",
    "class Length(layers.Layer):\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return K.sqrt(K.sum(K.square(inputs), -1) + K.epsilon())\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1]\n",
    "    \n",
    "    def get_config(self):\n",
    "        return super(Length, self).get_config()\n",
    "\n",
    "@tf.keras.saving.register_keras_serializable(package=\"Custom\")\n",
    "class CapsuleLayer(layers.Layer):\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_num_capsule = input_shape[1]\n",
    "        self.input_dim_capsule = input_shape[2]\n",
    "        \n",
    "        self.W = self.add_weight(\n",
    "            shape=[1, self.input_num_capsule, self.num_capsule, self.dim_capsule, self.input_dim_capsule],\n",
    "            initializer=initializers.glorot_uniform(),\n",
    "            name='W'\n",
    "        )\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs_expand = K.expand_dims(K.expand_dims(inputs, 2), 2)\n",
    "        W_tiled = K.tile(self.W, [K.shape(inputs)[0], 1, 1, 1, 1])\n",
    "        inputs_hat = tf.squeeze(tf.matmul(W_tiled, inputs_expand, transpose_b=True), axis=-1)\n",
    "        b = tf.zeros(shape=[K.shape(inputs)[0], self.input_num_capsule, self.num_capsule])\n",
    "\n",
    "        for i in range(self.routings):\n",
    "            c = tf.nn.softmax(b, axis=2)\n",
    "            c_expand = K.expand_dims(c, -1)\n",
    "            outputs = self.squash(tf.reduce_sum(inputs_hat * c_expand, axis=1))\n",
    "            if i < self.routings - 1:\n",
    "                b += tf.reduce_sum(inputs_hat * K.expand_dims(c, -1), axis=-1)\n",
    "        \n",
    "        return outputs\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_capsule\": self.num_capsule,\n",
    "            \"dim_capsule\": self.dim_capsule,\n",
    "            \"routings\": self.routings\n",
    "        })\n",
    "        return config\n",
    "    def squash(self, vectors, axis=-1):\n",
    "        s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n",
    "        scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm + K.epsilon())\n",
    "        return scale * vectors\n",
    "\n",
    "@tf.keras.saving.register_keras_serializable(package=\"Custom\", name=\"margin_loss\")\n",
    "def margin_loss(y_true, y_pred):\n",
    "    y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=2)\n",
    "    L = y_true * tf.square(tf.maximum(0., 0.9 - y_pred)) + \\\n",
    "        0.5 * (1 - y_true) * tf.square(tf.maximum(0., y_pred - 0.1))\n",
    "    return tf.reduce_mean(tf.reduce_sum(L, axis=1))\n",
    "\n",
    "class MobileNetCapsNet:\n",
    "    def __init__(self, input_shape=(224, 224, 3)):\n",
    "        self.input_shape = input_shape\n",
    "        self.model = self._build_model()\n",
    "    \n",
    "    def _build_model(self):\n",
    "        base_model = tf.keras.applications.MobileNetV2(\n",
    "            input_shape=self.input_shape,\n",
    "            include_top=False,\n",
    "            weights='imagenet'\n",
    "        )\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        x = base_model.output\n",
    "        x = layers.Conv2D(256, 3, activation='relu')(x)\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Reshape((-1, 256))(x)\n",
    "        \n",
    "        x = CapsuleLayer(num_capsule=8, dim_capsule=16, routings=3)(x)\n",
    "        x = CapsuleLayer(num_capsule=2, dim_capsule=32, routings=3)(x)\n",
    "        outputs = Length()(x)\n",
    "        \n",
    "        return tf.keras.Model(inputs=base_model.input, outputs=outputs)\n",
    "    \n",
    "    def compile_model(self, learning_rate=0.001):\n",
    "        \"\"\"Compile the model with appropriate loss and optimizer\"\"\"\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        \n",
    "        self.model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=self.margin_loss,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "    @staticmethod\n",
    "    def margin_loss(y_true, y_pred):\n",
    "        \"\"\"Margin loss for capsule network\"\"\"\n",
    "        # Convert y_true to one-hot if it isn't already\n",
    "        if len(K.int_shape(y_true)) == 1:\n",
    "            y_true = tf.one_hot(tf.cast(y_true, 'int32'), 2)\n",
    "            \n",
    "        L = y_true * tf.square(tf.maximum(0., 0.9 - y_pred)) + \\\n",
    "            0.5 * (1 - y_true) * tf.square(tf.maximum(0., y_pred - 0.1))\n",
    "        return tf.reduce_mean(tf.reduce_sum(L, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32a9d172-72d6-4683-9725-3776998466f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Major Project\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Major Project\\venv\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 6 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "Teacher_model_mobilenet_capsulenet = load_model(r\"C:\\Users\\GURU\\Downloads\\drowsiness_model_teacher_very_less_complex.keras\",custom_objects={\"CapsuleLayer\": CapsuleLayer,\"Length\":Length,\"margin_loss\":margin_loss})\n",
    "Vgg16_model = load_model(r\"D:\\Major Project\\Rasp\\model\\drowsiness_vgg_16_model_teacher_5_epoch.keras\")\n",
    "Student_model_pre = load_model(r\"C:\\Users\\GURU\\Downloads\\drowsiness_model_student.keras\",custom_objects={\"CapsuleLayer\": CapsuleLayer,\"Length\":Length,\"margin_loss\":margin_loss})\n",
    "Student_model_post = load_model(r\"C:\\Users\\GURU\\Downloads\\drowsiness_model_student_Distilled_5_epoch.keras\",custom_objects={\"CapsuleLayer\": CapsuleLayer,\"Length\":Length,\"margin_loss\":margin_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a0b9bc9-a04e-4015-bf60-2961b1e96e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Teacher (MobileNet+CapsNet)\": Teacher_model_mobilenet_capsulenet,\n",
    "    \"VGG16\": Vgg16_model,\n",
    "    \"Student Pre-KD\": Student_model_pre,\n",
    "    \"Student Post-KD\": Student_model_post\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ceed5f9-b2ce-4d46-a0ff-9572c6e3b59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_curve, auc, precision_recall_curve, average_precision_score, confusion_matrix\n",
    ")\n",
    "\n",
    "def evaluate_all_models(models, dataset_dir):\n",
    "    results = {}\n",
    "\n",
    "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "    test_gen = test_datagen.flow_from_directory(\n",
    "        dataset_dir,\n",
    "        target_size=INPUT_SHAPE[:2],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    y_true = test_gen.classes.astype(int)\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"Evaluating: {name}\")\n",
    "\n",
    "        y_raw = model.predict(test_gen)\n",
    "        if y_raw.shape[-1] == 1:\n",
    "            # Binary classification: sigmoid output\n",
    "            y_prob = y_raw.ravel()\n",
    "            y_pred = (y_prob > 0.5).astype(int)\n",
    "        elif y_raw.shape[-1] == 2 and len(np.unique(y_true)) == 2:\n",
    "            # Binary classification: softmax output over 2 classes\n",
    "            y_prob = y_raw[:, 1]  # Probability of class 1 (Drowsy)\n",
    "            y_pred = np.argmax(y_raw, axis=1)\n",
    "        else:\n",
    "            # Multi-class case\n",
    "            y_prob = y_raw\n",
    "            y_pred = np.argmax(y_prob, axis=1)\n",
    "        # if y_raw.shape[-1] == 1:\n",
    "        #     # Binary classification: sigmoid\n",
    "        #     y_prob = y_raw.ravel()\n",
    "        #     y_pred = (y_prob > 0.5).astype(int)\n",
    "        # elif y_raw.shape[-1] == 2 and len(np.unique(y_true)) == 2:\n",
    "        #     # Binary classification: softmax output over 2 classes\n",
    "        #     y_prob = y_raw[:, 1]  # Use probability of class 1 (Drowsy)\n",
    "        #     y_pred = np.argmax(y_raw, axis=1)\n",
    "        # else:\n",
    "        #     # Multi-class case\n",
    "        #     y_prob = y_raw\n",
    "        #     y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "        # Classification metrics\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred, average='binary' if y_prob.ndim == 1 or y_prob.shape[1] == 1 else 'macro')\n",
    "        rec = recall_score(y_true, y_pred, average='binary' if y_prob.ndim == 1 or y_prob.shape[1] == 1 else 'macro')\n",
    "        f1 = f1_score(y_true, y_pred, average='binary' if y_prob.ndim == 1 or y_prob.shape[1] == 1 else 'macro')\n",
    "\n",
    "        # ROC & PR curve (only for binary)\n",
    "        if y_prob.ndim == 1 or y_prob.shape[1] == 1:\n",
    "            fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "            auc_score = auc(fpr, tpr)\n",
    "            pr, rc, _ = precision_recall_curve(y_true, y_prob)\n",
    "            avg_pr = average_precision_score(y_true, y_prob)\n",
    "\n",
    "        else:\n",
    "            fpr, tpr, auc_score = None, None, None\n",
    "            pr, rc, avg_pr = None, None, None\n",
    "\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "\n",
    "        results[name] = {\n",
    "            'accuracy': acc,\n",
    "            'precision': prec,\n",
    "            'recall': rec,\n",
    "            'f1': f1,\n",
    "            'roc': (fpr, tpr, auc_score),\n",
    "            'pr': (rc, pr, avg_pr),\n",
    "            'confusion_matrix': cm,\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "            'y_prob': y_prob\n",
    "        }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eaa2ed9-6edf-4289-a28c-6689bccde4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_all_comparisons(results_dict):\n",
    "    model_names = list(results_dict.keys())\n",
    "\n",
    "    # Accuracy / Top-1\n",
    "    acc = [results_dict[name]['accuracy'] for name in model_names]\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    x = np.arange(len(model_names))\n",
    "    plt.bar(x, acc, label='Accuracy', color='skyblue')\n",
    "    plt.xticks(x, model_names)\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Model Accuracy Comparison')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Precision / Recall / F1\n",
    "    precs = [results_dict[name]['precision'] for name in model_names]\n",
    "    recs = [results_dict[name]['recall'] for name in model_names]\n",
    "    f1s = [results_dict[name]['f1'] for name in model_names]\n",
    "\n",
    "    plt.figure(figsize=(9,5))\n",
    "    x = np.arange(len(model_names))\n",
    "    width = 0.25\n",
    "    plt.bar(x - width, precs, width, label='Precision')\n",
    "    plt.bar(x, recs, width, label='Recall')\n",
    "    plt.bar(x + width, f1s, width, label='F1 Score')\n",
    "    plt.xticks(x, model_names)\n",
    "    plt.title(\"Precision / Recall / F1\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for name in model_names:\n",
    "        fpr, tpr, auc_score = results_dict[name]['roc']\n",
    "        \n",
    "        # Only plot if fpr and tpr are valid (not None)\n",
    "        if fpr is not None and tpr is not None:\n",
    "            if auc_score is not None:\n",
    "                plt.plot(fpr, tpr, label=f\"{name} (AUC = {auc_score:.2f})\")\n",
    "            else:\n",
    "                plt.plot(fpr, tpr, label=f\"{name} (AUC not available)\")\n",
    "        else:\n",
    "            plt.plot([0, 1], [0, 1], 'k--', label=f\"{name} (No ROC data)\")\n",
    "            \n",
    "    plt.plot([0,1], [0,1], 'k--')\n",
    "    plt.title(\"ROC Curves\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # PR Curve\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for name in model_names:\n",
    "        rc, pr, avg_pr = results_dict[name]['pr']\n",
    "        plt.plot(rc, pr, label=f\"{name} (AP = {avg_pr:.2f})\")\n",
    "    plt.title(\"Precision-Recall Curves\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Confusion Matrices\n",
    "    n = len(model_names)\n",
    "    cols = 2\n",
    "    rows = (n + 1) // cols\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(10, 4 * rows))\n",
    "\n",
    "    for i, name in enumerate(model_names):\n",
    "        ax = axs[i // cols, i % cols] if rows > 1 else axs[i]\n",
    "        cm = results_dict[name]['confusion_matrix']\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=['Not Drowsy', 'Drowsy'],\n",
    "                    yticklabels=['Not Drowsy', 'Drowsy'],\n",
    "                    ax=ax)\n",
    "        ax.set_title(f\"{name} - Confusion Matrix\")\n",
    "        ax.set_xlabel(\"Predicted\")\n",
    "        ax.set_ylabel(\"Actual\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "944122a2-0462-4113-af3c-289ead16e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (224, 224, 3)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 0.001\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "096c9704-7d94-4468-b01c-92ea2f08c358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2374 images belonging to 2 classes.\n",
      "Evaluating: Teacher (MobileNet+CapsNet)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Major Project\\venv\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 413ms/step\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'average' parameter of precision_score must be a str among {'micro', 'samples', 'binary', 'macro', 'weighted'} or None. Got 'categorical' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_all_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD:/Major Project/Rasp/Final_Results_MEtrcs/test\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 53\u001b[0m, in \u001b[0;36mevaluate_all_models\u001b[1;34m(models, dataset_dir)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# if y_raw.shape[-1] == 1:\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#     # Binary classification: sigmoid\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m#     y_prob = y_raw.ravel()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m \n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Classification metrics\u001b[39;00m\n\u001b[0;32m     52\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(y_true, y_pred)\n\u001b[1;32m---> 53\u001b[0m prec \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcategorical\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my_prob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my_prob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmacro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m rec \u001b[38;5;241m=\u001b[39m recall_score(y_true, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_prob\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y_prob\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     55\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(y_true, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_prob\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y_prob\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\Major Project\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:206\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m to_ignore \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    204\u001b[0m params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m to_ignore}\n\u001b[1;32m--> 206\u001b[0m \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameter_constraints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__qualname__\u001b[39;49m\n\u001b[0;32m    208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n",
      "File \u001b[1;32mD:\\Major Project\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:98\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     96\u001b[0m     )\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m )\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'average' parameter of precision_score must be a str among {'micro', 'samples', 'binary', 'macro', 'weighted'} or None. Got 'categorical' instead."
     ]
    }
   ],
   "source": [
    "results = evaluate_all_models(models, dataset_dir=r\"D:\\Major Project\\Rasp\\old\\test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e26a19-a25c-4bb9-8552-8fa8de6a525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_comparisons(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba725f23-84f5-4e7b-b2d8-3153f5a7676c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74a563b-79c5-4165-a130-3b671b5a539f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
