{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bac31f7-f2f5-40d3-b11c-64fb2fcbf15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import struct\n",
    "import zlib\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "# from tensorflow.keras.saving import register_keras_serializable\n",
    "from tensorflow.keras import layers, initializers, backend as K\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from cryptography.fernet import Fernet\n",
    "import base64\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98acb726-c6ea-40c9-9dbb-13f6442202b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, initializers, backend as K\n",
    "\n",
    "# **Custom Capsule Layers**\n",
    "class Length(layers.Layer):\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return K.sqrt(K.sum(K.square(inputs), -1) + K.epsilon())\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1]\n",
    "\n",
    "class CapsuleLayer(layers.Layer):\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3, **kwargs):\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_num_capsule = input_shape[1]\n",
    "        self.input_dim_capsule = input_shape[2]\n",
    "        self.W = self.add_weight(\n",
    "            shape=[1, self.input_num_capsule, self.num_capsule, self.dim_capsule, self.input_dim_capsule],\n",
    "            initializer=initializers.glorot_uniform(),\n",
    "            name='W'\n",
    "        )\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs_expand = K.expand_dims(K.expand_dims(inputs, 2), 2)\n",
    "        W_tiled = K.tile(self.W, [K.shape(inputs)[0], 1, 1, 1, 1])\n",
    "        inputs_hat = tf.squeeze(tf.matmul(W_tiled, inputs_expand, transpose_b=True), axis=-1)\n",
    "        b = tf.zeros(shape=[K.shape(inputs)[0], self.input_num_capsule, self.num_capsule])\n",
    "\n",
    "        for i in range(self.routings):\n",
    "            c = tf.nn.softmax(b, axis=2)\n",
    "            outputs = tf.reduce_sum(inputs_hat * K.expand_dims(c, -1), axis=1)\n",
    "            if i < self.routings - 1:\n",
    "                b += tf.reduce_sum(inputs_hat * K.expand_dims(c, -1), axis=-1)\n",
    "        return outputs\n",
    "\n",
    "# **Build MobileNet + Capsule Model**\n",
    "class MobileNetCapsNet:\n",
    "    def __init__(self, input_shape=(224, 224, 3)):\n",
    "        self.input_shape = input_shape\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        base_model = tf.keras.applications.MobileNetV2(\n",
    "            input_shape=self.input_shape,\n",
    "            include_top=False,\n",
    "            weights='imagenet'\n",
    "        )\n",
    "        base_model.trainable = False  # Freeze MobileNet\n",
    "\n",
    "        x = base_model.output\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Reshape((-1, 64))(x)\n",
    "        x = CapsuleLayer(num_capsule=2, dim_capsule=8, routings=1)(x)\n",
    "        outputs = Length()(x)\n",
    "\n",
    "        return tf.keras.Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "# **Margin Loss Function**\n",
    "def margin_loss(y_true, y_pred):\n",
    "    y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=2)\n",
    "    L = y_true * tf.square(tf.maximum(0., 0.9 - y_pred)) + \\\n",
    "        0.5 * (1 - y_true) * tf.square(tf.maximum(0., y_pred - 0.1))\n",
    "    return tf.reduce_mean(tf.reduce_sum(L, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30bc8a7c-6f98-4c05-8079-f0f9fe3bda0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Major Project\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.load_model(r\"D:\\Major Project\\Final Proper\\drowsiness_lesser_india_plus_eye.keras\",custom_objects={\"CapsuleLayer\": CapsuleLayer,\"Length\":Length,\"margin_loss\":margin_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5437094-2df4-457b-aaf5-3ff6403a21bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dc1b66-82d1-4e44-91e9-afe8e11b7888",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import mediapipe as mp\n",
    "\n",
    "# **Load MediaPipe Face Mesh**\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "# **Load Pretrained Model**\n",
    "model = model# Ensure the path is correct\n",
    "print(\"‚úÖ Model loaded successfully!\")\n",
    "\n",
    "# **Get Input Folder from User**\n",
    "input_folder = r\"D:\\Major Project\\Rasp\\Final_Results_MEtrcs\\Client_datasert\\drowsy\"  # Update the input directory\n",
    "\n",
    "# **Check if the directory exists**\n",
    "if not os.path.exists(input_folder):\n",
    "    print(f\"‚ùå Error: The directory '{input_folder}' does not exist.\")\n",
    "    exit()\n",
    "start=r\"D:\\Major Project\\Rasp\\Final_Results_MEtrcs\\Clientssdata\"\n",
    "# **Define Output Folders**\n",
    "output_base = os.path.join(start, \"Dataset_Classified\")\n",
    "drowsy_folder = os.path.join(output_base, \"drowsy\")\n",
    "non_drowsy_folder = os.path.join(output_base, \"non_drowsy\")\n",
    "uncertain_folder = os.path.join(output_base, \"uncertain\")\n",
    "\n",
    "# **Create Output Folders if They Don't Exist**\n",
    "os.makedirs(drowsy_folder, exist_ok=True)\n",
    "os.makedirs(non_drowsy_folder, exist_ok=True)\n",
    "os.makedirs(uncertain_folder, exist_ok=True)\n",
    "\n",
    "# **Class Labels Mapping**\n",
    "CLASS_LABELS = {\n",
    "    0: \"Eyes Closed\",   # Drowsy\n",
    "    1: \"Happy\",         # Non-Drowsy\n",
    "    2: \"Neutral\",       # Non-Drowsy\n",
    "    3: \"Yawning\"        # Drowsy\n",
    "}\n",
    "\n",
    "# **Preprocessing Function**\n",
    "def preprocess_image(img, target_size=(224, 224)):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img / 255.0  # Normalize\n",
    "    return np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "# **Confidence Threshold**\n",
    "CONFIDENCE_THRESHOLD = 75  \n",
    "\n",
    "# **Process Images in the Input Folder**\n",
    "for subdir, _, files in os.walk(input_folder):\n",
    "    for filename in files:\n",
    "        img_path = os.path.join(subdir, filename)\n",
    "\n",
    "        # **Skip Non-Image Files**\n",
    "        if not filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"‚ö†Ô∏è Skipping {filename} (Could not read image)\")\n",
    "            continue\n",
    "\n",
    "        h, w, _ = img.shape\n",
    "\n",
    "        # **Detect face mesh using MediaPipe**\n",
    "        rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(rgb_img)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                # **Extract Eye Landmarks**\n",
    "                left_eye_top = face_landmarks.landmark[159]\n",
    "                left_eye_bottom = face_landmarks.landmark[145]\n",
    "                right_eye_top = face_landmarks.landmark[386]\n",
    "                right_eye_bottom = face_landmarks.landmark[374]\n",
    "\n",
    "                left_eye_opening = int((left_eye_bottom.y - left_eye_top.y) * h)\n",
    "                right_eye_opening = int((right_eye_bottom.y - right_eye_top.y) * h)\n",
    "\n",
    "                # **Eye openness threshold**\n",
    "                eye_threshold = 5  # Adjust based on testing\n",
    "                avg_eye_opening = (left_eye_opening + right_eye_opening) / 2\n",
    "\n",
    "                # **Extract Mouth Landmarks**\n",
    "                upper_lip_top = face_landmarks.landmark[13]\n",
    "                lower_lip_bottom = face_landmarks.landmark[14]\n",
    "\n",
    "                mouth_opening = int((lower_lip_bottom.y - upper_lip_top.y) * h)\n",
    "\n",
    "                # **Preprocess Image & Predict Using Model**\n",
    "                img_array = preprocess_image(img)\n",
    "                prediction = model.predict(img_array)  # Model prediction\n",
    "                class_id = np.argmax(prediction)  # Get class index\n",
    "                confidence = round(max(prediction[0]) * 100, 2)  # Get highest probability\n",
    "\n",
    "                # **Drowsiness Classification Logic**\n",
    "                if avg_eye_opening < eye_threshold or class_id == 0:\n",
    "                    status = \"Drowsy\"\n",
    "                    target_folder = drowsy_folder\n",
    "                elif mouth_opening > 15 and class_id == 3:\n",
    "                    status = \"Drowsy\"\n",
    "                    target_folder = drowsy_folder\n",
    "                else:\n",
    "                    status = \"Non-Drowsy\"\n",
    "                    target_folder = non_drowsy_folder\n",
    "\n",
    "                # **Sort Based on Confidence Level**\n",
    "                if confidence >= CONFIDENCE_THRESHOLD:\n",
    "                    print(f\"‚úÖ {filename} ‚Üí {CLASS_LABELS[class_id]} ({status}) (Confidence: {confidence}%)\")\n",
    "                    shutil.copy2(img_path, os.path.join(target_folder, filename))\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Uncertain: {filename} (Confidence: {confidence}%) - Below threshold\")\n",
    "                    shutil.copy2(img_path, os.path.join(uncertain_folder, filename))\n",
    "        else:\n",
    "            print(f\"üö´ No face detected in {filename}. Marking as uncertain.\")\n",
    "            shutil.copy2(img_path, os.path.join(uncertain_folder, filename))\n",
    "\n",
    "print(\"\\n‚úÖ Classification completed! High-confidence images sorted, uncertain ones stored separately.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429d2fe3-9552-4da3-a628-b6f2df33a8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
