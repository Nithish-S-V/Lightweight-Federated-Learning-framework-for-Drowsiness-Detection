{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c2d1eff-03e2-447c-a451-522ac2ee3259",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (224, 224, 3)\n",
    "BATCH_SIZE = 32\n",
    "TEST_DIR = r\"D:\\Major Project\\Final Proper\\3class_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae4f319f-3186-4f20-9911-4ffbb6dadcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import struct\n",
    "import zlib\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "from tensorflow.keras import layers, initializers, backend as K\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from cryptography.fernet import Fernet\n",
    "import base64\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b64dc0e0-addc-42c1-8d83-e5f7a784ea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Capsule Network Components\n",
    "@register_keras_serializable(package=\"Custom\")\n",
    "class Length(layers.Layer):\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return K.sqrt(K.sum(K.square(inputs), -1) + K.epsilon())\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1]\n",
    "    \n",
    "    def get_config(self):\n",
    "        return super(Length, self).get_config()\n",
    "\n",
    "@tf.keras.saving.register_keras_serializable(package=\"Custom\")\n",
    "class CapsuleLayer(layers.Layer):\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_num_capsule = input_shape[1]\n",
    "        self.input_dim_capsule = input_shape[2]\n",
    "        \n",
    "        self.W = self.add_weight(\n",
    "            shape=[1, self.input_num_capsule, self.num_capsule, self.dim_capsule, self.input_dim_capsule],\n",
    "            initializer=initializers.glorot_uniform(),\n",
    "            name='W'\n",
    "        )\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs_expand = K.expand_dims(K.expand_dims(inputs, 2), 2)\n",
    "        W_tiled = K.tile(self.W, [K.shape(inputs)[0], 1, 1, 1, 1])\n",
    "        inputs_hat = tf.squeeze(tf.matmul(W_tiled, inputs_expand, transpose_b=True), axis=-1)\n",
    "        b = tf.zeros(shape=[K.shape(inputs)[0], self.input_num_capsule, self.num_capsule])\n",
    "\n",
    "        for i in range(self.routings):\n",
    "            c = tf.nn.softmax(b, axis=2)\n",
    "            c_expand = K.expand_dims(c, -1)\n",
    "            outputs = self.squash(tf.reduce_sum(inputs_hat * c_expand, axis=1))\n",
    "            if i < self.routings - 1:\n",
    "                b += tf.reduce_sum(inputs_hat * K.expand_dims(c, -1), axis=-1)\n",
    "        \n",
    "        return outputs\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_capsule\": self.num_capsule,\n",
    "            \"dim_capsule\": self.dim_capsule,\n",
    "            \"routings\": self.routings\n",
    "        })\n",
    "        return config\n",
    "    def squash(self, vectors, axis=-1):\n",
    "        s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n",
    "        scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm + K.epsilon())\n",
    "        return scale * vectors\n",
    "\n",
    "@tf.keras.saving.register_keras_serializable(package=\"Custom\", name=\"margin_loss\")\n",
    "def margin_loss(y_true, y_pred):\n",
    "    # Remove explicit one-hot conversion if labels are already categorical\n",
    "    if len(y_true.shape) == 2:  # Already one-hot encoded\n",
    "        y_true_ = y_true\n",
    "    else:  # Convert sparse labels to one-hot\n",
    "        y_true_ = tf.one_hot(tf.cast(y_true, tf.int32), depth=2)\n",
    "    \n",
    "    L = y_true_ * tf.square(tf.maximum(0., 0.9 - y_pred)) + \\\n",
    "        0.5 * (1 - y_true_) * tf.square(tf.maximum(0., y_pred - 0.1))\n",
    "    return tf.reduce_mean(tf.reduce_sum(L, axis=1))\n",
    "\n",
    "\n",
    "class MobileNetCapsNet:\n",
    "    def __init__(self, input_shape=(224, 224, 3)):\n",
    "        self.input_shape = input_shape\n",
    "        self.model = self._build_model()\n",
    "    \n",
    "    def _build_model(self):\n",
    "        base_model = tf.keras.applications.MobileNetV2(\n",
    "            input_shape=self.input_shape,\n",
    "            include_top=False,\n",
    "            weights='imagenet'\n",
    "        )\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        x = base_model.output\n",
    "        x = layers.Conv2D(256, 3, activation='relu')(x)\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Reshape((-1, 256))(x)\n",
    "        \n",
    "        x = CapsuleLayer(num_capsule=8, dim_capsule=16, routings=3)(x)\n",
    "        x = CapsuleLayer(num_capsule=2, dim_capsule=32, routings=3)(x)\n",
    "        outputs = Length()(x)\n",
    "        \n",
    "        return tf.keras.Model(inputs=base_model.input, outputs=outputs)\n",
    "    \n",
    "    def compile_model(self, learning_rate=0.001):\n",
    "        \"\"\"Compile the model with appropriate loss and optimizer\"\"\"\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        \n",
    "        self.model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=self.margin_loss,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "    @staticmethod\n",
    "    def margin_loss(y_true, y_pred):\n",
    "        \"\"\"Margin loss for capsule network\"\"\"\n",
    "        # Convert y_true to one-hot if it isn't already\n",
    "        if len(K.int_shape(y_true)) == 1:\n",
    "            y_true = tf.one_hot(tf.cast(y_true, 'int32'), 2)\n",
    "            \n",
    "        L = y_true * tf.square(tf.maximum(0., 0.9 - y_pred)) + \\\n",
    "            0.5 * (1 - y_true) * tf.square(tf.maximum(0., y_pred - 0.1))\n",
    "        return tf.reduce_mean(tf.reduce_sum(L, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b43acc61-95f5-4d4a-adb4-cf1403aa6072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "def load_model_from_file():\n",
    "    return load_model(r\"D:\\Major Project\\Final Proper\\Models\\drowsiness_model_final_final_lesser.keras\", \n",
    "                      custom_objects={\"CapsuleLayer\": CapsuleLayer,\"Length\":Length,\"margin_loss\":margin_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c1c4434-6f5a-4f55-a63c-a7b95f177090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset_dir):\n",
    "# Define test image generator\n",
    "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # Load test images\n",
    "    test_gen = test_datagen.flow_from_directory(\n",
    "        dataset_dir,\n",
    "        target_size=INPUT_SHAPE[:2],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',  \n",
    "        color_mode='rgb',\n",
    "        shuffle=False\n",
    "    )\n",
    "    # Get predictions (probabilities)\n",
    "    # Get predictions (probabilities)\n",
    "    y_pred = np.argmax(model.predict(test_gen), axis=1)\n",
    "    y_true = test_gen.classes\n",
    "\n",
    "    print(\"\\nTest Metrics:\")\n",
    "    print(f\"Accuracy: {np.mean(y_true == y_pred):.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['Eyeclose','Neutral', 'Yawn'], zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d1dd8e2-0d60-48a9-9090-19a7ef0d78a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Major Project\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "global_model = load_model_from_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66bd1813-b136-43bc-8663-69eda0b4d01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1117 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Major Project\\venv\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 107ms/step\n",
      "\n",
      "Test Metrics:\n",
      "Accuracy: 0.9651\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Eyeclose       0.98      0.99      0.98       382\n",
      "     Neutral       0.94      0.98      0.96       461\n",
      "        Yawn       1.00      0.90      0.95       274\n",
      "\n",
      "    accuracy                           0.97      1117\n",
      "   macro avg       0.97      0.96      0.96      1117\n",
      "weighted avg       0.97      0.97      0.96      1117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(global_model, r\"D:\\Major Project\\final datset\\test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39743804-b5fc-4e2f-9392-207875833313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Dataset directory\n",
    "DATASET_DIR = \"D:\\Major Project\\Final Proper\\Centralized dataset\\Centralized\"\n",
    "LEARNING_RATE = 0.001\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 1\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    \"\"\"Plot a confusion matrix.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8d8c385-4248-46b7-b258-f0b908ee797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_incremental_model():\n",
    "    rounds = sorted([os.path.join(DATASET_DIR, d) for d in os.listdir(DATASET_DIR) if d.startswith(\"set\")])\n",
    "    \n",
    "    model = global_model  # Ensure MobileNetCapsNet is defined\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(LEARNING_RATE),\n",
    "        loss=margin_loss,  # Ensure margin_loss is defined\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    for i, round_dir in enumerate(rounds):\n",
    "        print(f\"\\nTraining on {round_dir} (Round {i+1}/{len(rounds)})\")\n",
    "\n",
    "        datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=20,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    validation_split=0.2,        \n",
    "                )\n",
    "        train_flow = datagen.flow_from_directory(\n",
    "            round_dir,\n",
    "            target_size=INPUT_SHAPE[:2],\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode='categorical',  # Change from 'binary' to 'categorical'\n",
    "            color_mode='rgb',\n",
    "            subset='training',\n",
    "            shuffle=True \n",
    "        )\n",
    "    \n",
    "        val_flow = datagen.flow_from_directory(\n",
    "            round_dir,\n",
    "            target_size=INPUT_SHAPE[:2],\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode='categorical',  # Change from 'binary' to 'categorical'\n",
    "            color_mode='rgb',\n",
    "            subset='validation'\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            train_flow,\n",
    "            validation_data=val_flow,\n",
    "            epochs=EPOCHS,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # After training on each round, evaluate the model\n",
    "        print(f\"\\nEvaluating after training Set {i+1}\")\n",
    "        test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "        test_gen = test_datagen.flow_from_directory(\n",
    "            TEST_DIR,\n",
    "            target_size=INPUT_SHAPE[:2],\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode='categorical',  # Change from 'binary' to 'categorical'\n",
    "            color_mode='rgb',\n",
    "            shuffle=False\n",
    "        )\n",
    "        # Get predictions (probabilities)\n",
    "        # Get predictions (probabilities)\n",
    "        # Get predictions (probabilities)\n",
    "        y_pred = np.argmax(model.predict(test_gen), axis=1)\n",
    "        y_true = test_gen.classes\n",
    "    \n",
    "        print(\"\\nTest Metrics:\")\n",
    "        print(f\"Accuracy: {np.mean(y_true == y_pred):.4f}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_true, y_pred, target_names=['Eyeclose','Neutral', 'Yawn'], zero_division=0))\n",
    "        # Plot confusion matrix\n",
    "        plot_confusion_matrix(y_true, y_pred, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5b5a947-356e-4e4c-b8fd-d38085f7eab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on D:\\Major Project\\Final Proper\\Centralized dataset\\Centralized\\set1 (Round 1/5)\n",
      "Found 576 images belonging to 3 classes.\n",
      "Found 142 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Major Project\\venv\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 2 and 3 for '{{node compile_loss/margin_loss/mul}} = Mul[T=DT_FLOAT](compile_loss/margin_loss/one_hot, compile_loss/margin_loss/Square)' with input shapes: [?,3,2], [?,3].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_incremental_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 41\u001b[0m, in \u001b[0;36mtrain_incremental_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m train_flow \u001b[38;5;241m=\u001b[39m datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     23\u001b[0m     round_dir,\n\u001b[0;32m     24\u001b[0m     target_size\u001b[38;5;241m=\u001b[39mINPUT_SHAPE[:\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m \n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     32\u001b[0m val_flow \u001b[38;5;241m=\u001b[39m datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     33\u001b[0m     round_dir,\n\u001b[0;32m     34\u001b[0m     target_size\u001b[38;5;241m=\u001b[39mINPUT_SHAPE[:\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m     subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     39\u001b[0m )\n\u001b[1;32m---> 41\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_flow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_flow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     46\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# After training on each round, evaluate the model\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvaluating after training Set \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Major Project\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[3], line 62\u001b[0m, in \u001b[0;36mmargin_loss\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39msaving\u001b[38;5;241m.\u001b[39mregister_keras_serializable(package\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustom\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmargin_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmargin_loss\u001b[39m(y_true, y_pred):\n\u001b[0;32m     61\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mone_hot(tf\u001b[38;5;241m.\u001b[39mcast(y_true, tf\u001b[38;5;241m.\u001b[39mint32), depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 62\u001b[0m     L \u001b[38;5;241m=\u001b[39m \u001b[43my_true\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msquare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m y_true) \u001b[38;5;241m*\u001b[39m tf\u001b[38;5;241m.\u001b[39msquare(tf\u001b[38;5;241m.\u001b[39mmaximum(\u001b[38;5;241m0.\u001b[39m, y_pred \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.1\u001b[39m))\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39mreduce_sum(L, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 2 and 3 for '{{node compile_loss/margin_loss/mul}} = Mul[T=DT_FLOAT](compile_loss/margin_loss/one_hot, compile_loss/margin_loss/Square)' with input shapes: [?,3,2], [?,3]."
     ]
    }
   ],
   "source": [
    "train_incremental_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6c7068-332d-43b9-981d-dfdd1a1e18c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
